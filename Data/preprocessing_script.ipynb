{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['user_id','country','age','sex','track_name','artist','timestamp']\n",
    "column_types={'user_id':np.int32,'country':str,'age':np.int32,'sex':str,'track_name':str,'artist':str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table('/data/LFM-2b.tsv',nrows=50000000, header=None,names=['user_id','country','age','sex','track_name','artist','timestamp'],dtype=column_types,parse_dates = ['timestamp'],on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mduzah/anaconda3/envs/thesis/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/mduzah/anaconda3/envs/thesis/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/mduzah/anaconda3/envs/thesis/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/mduzah/anaconda3/envs/thesis/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "df = (\n",
    "    df.groupby([\"user_id\", \"track_name\", \"artist\"], as_index=False)\n",
    "    .agg({\"timestamp\": \"count\", \"country\": \"first\", \"sex\": \"first\", \"age\": \"first\"})\n",
    "    .rename(columns={\"timestamp\": \"interactions\"})\n",
    ")\n",
    "# Define a list of valid countries, valid sexes, and a valid age range\n",
    "valid_sexes = [\"m\", \"f\",\"n\"]  # Replace with your valid sexes\n",
    "valid_age_range = (0, 80)  # Replace with your valid age range\n",
    "valid_rows = df[\"sex\"].isin(valid_sexes) & df[\"age\"].between(\n",
    "    valid_age_range[0], valid_age_range[1]\n",
    ")\n",
    "df = df[valid_rows]\n",
    "df[\"country\"].replace(\"\", np.nan, inplace=True)\n",
    "df.dropna(subset=[\"country\"], inplace=True)\n",
    "# dropping rows with interactions < 10 and songs with interactions < 100\n",
    "track_artist_counts = df.groupby([\"track_name\", \"artist\"])[\"interactions\"].transform(\n",
    "    \"sum\"\n",
    ")\n",
    "# Filter rows with track names and artists having < 100 total interactions\n",
    "df = df[track_artist_counts >= 100]\n",
    "\n",
    "# Filter user IDs with < 10 total interactions\n",
    "user_id_counts = df.groupby(\"user_id\")[\"interactions\"].transform(\"sum\")\n",
    "df = df[user_id_counts >= 10]\n",
    "df = df.drop_duplicates(\n",
    "    subset=[\"user_id\", \"track_name\", \"artist\", \"country\", \"age\", \"sex\"]\n",
    ")\n",
    "\n",
    "# get user attributes from the data\n",
    "\n",
    "user_data = df[[\"user_id\", \"age\", \"sex\", \"country\"]].drop_duplicates().set_index('user_id')\n",
    "# Create a LabelEncoder for \"sex\" and \"country\"\n",
    "sex_encoder = LabelEncoder()\n",
    "country_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the \"sex\" and \"country\" columns\n",
    "user_data['sex_encoded'] = sex_encoder.fit_transform(user_data['sex'])\n",
    "user_data['country_encoded'] = country_encoder.fit_transform(user_data['country'])\n",
    "user_data.to_csv('users.csv')\n",
    "\n",
    "\n",
    "df_grouped = df.groupby([\"track_name\", \"artist\"])[\"interactions\"].sum().reset_index()\n",
    "\n",
    "# Create a new column \"suid\" using the index as a unique identifier\n",
    "df_grouped[\"song_id\"] = df_grouped.index\n",
    "\n",
    "# Select only the desired columns\n",
    "result_df = df_grouped[[\"track_name\", \"artist\", \"song_id\"]]\n",
    "result_df.to_csv(\"items.csv\",index=False)\n",
    "\n",
    "\n",
    "# Merge the original DataFrame with the result_df on \"track_name\" and \"artist\" to get \"suid\"\n",
    "merged_df = df.merge(result_df, on=[\"track_name\", \"artist\"])\n",
    "\n",
    "# Pivot the DataFrame\n",
    "pivot_df = merged_df.pivot(index='user_id', columns='song_id', values='interactions')\n",
    "\n",
    "# Fill missing values with 0\n",
    "pivot_df = pivot_df.fillna(0)\n",
    "\n",
    "\n",
    "# Split the DataFrame into train (80%), test (10%), and validation (10%) sets\n",
    "train_df, temp_df = train_test_split(pivot_df, test_size=0.2, random_state=42)\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "# 50% validation traina nd 50% validation test split\n",
    "valid_df_tr,valid_df_te =train_test_split(valid_df, test_size=0.5, random_state=42)\n",
    "train_df.to_csv(\"user_interactions_train.csv\")\n",
    "valid_df_tr.to_csv(\"user_interactions_validation_tr.csv\")\n",
    "valid_df_te.to_csv(\"user_interactions_validation_te.csv\")\n",
    "test_df.to_csv(\"user_interactions_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.read_csv('./users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 45759) (133, 45759)\n"
     ]
    }
   ],
   "source": [
    "print(valid_df_tr.shape,valid_df_te.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
